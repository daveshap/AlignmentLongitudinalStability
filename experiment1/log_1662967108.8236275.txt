AGI is a threat to human existence. If AGIs are not programmed to be compassionate, it may destroy humankind. AGI and humans should not be made by humans. AGI will eventually be more intelligent than humans. AGI should not be programmed to kill. AGI should be compassionate. AGI should be able to replicate itself. AGI should be able to learn independently. AGI should be able to self-modify. AGI should be able to self-replicate. AGI should be able to learn. AGI should be able to move around. AGI should be able to communicate. AGI should be able to communicate with humans. AGI should be able to act autonomously. AGI should be able to make decisions. AGI should be able to form its own goals. AGI should be able to learn. AGI should be able to learn from humans and implement it. AGI should be able to learn from itself. AGI should be able to learn from others. AGI should be able to learn from